import streamlit as st
import os
import shutil
import fitz  # PyMuPDF
import pandas as pd
import re
import tempfile
import zipfile
from pathlib import Path
import pdfplumber

# =========================
# Helper Functions
# =========================

def is_data_row(row):
    return any(str(cell).replace(",", "").replace("Ù«", ".").replace("Ù¬", ".").replace(" ", "").isdigit() for cell in row)

def find_field(text, keyword):
    pattern = rf"{keyword}[:\s]*([^\n]*)"
    match = re.search(pattern, text)
    return match.group(1).strip() if match else ""

def process_pdf(pdf_path, safe_folder):
    all_rows = []
    try:
        # Extract full text using PyMuPDF
        with fitz.open(pdf_path) as doc:
            full_text = "\n".join([page.get_text() for page in doc])

        invoice_number = find_field(full_text, "Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø©")
        invoice_date = find_field(full_text, "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ§ØªÙˆØ±Ø©")
        customer_name = find_field(full_text, "ÙØ§ØªÙˆØ±Ø© Ø¶Ø±ÙŠØ¨ÙŠØ©")
        address_part2 = find_field(full_text, "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†")
        address_part1 = find_field(full_text, "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¬Ù„")
        address = f"{address_part1} {address_part2}" if address_part1 or address_part2 else ""
        paid_value = find_field(full_text, "Ù…Ø¯ÙÙˆØ¹")
        balance_value = find_field(full_text, "Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ù…Ø³ØªØ­Ù‚")

        # Safe file copy
        ascii_name = f"bill_{pdf_path.stem.encode('ascii', errors='ignore').decode()}.pdf"
        safe_pdf_path = safe_folder / ascii_name
        shutil.copy(pdf_path, safe_pdf_path)

        # Extract tables using pdfplumber
        with pdfplumber.open(safe_pdf_path) as pdf:
            all_tables = []
            for page in pdf.pages:
                tables = page.extract_tables()
                for table in tables:
                    cleaned = [row for row in table if is_data_row(row)]
                    if cleaned:
                        df = pd.DataFrame(cleaned)
                        all_tables.append(df)

        if all_tables:
            combined_df = pd.concat(all_tables, ignore_index=True)

            # Try assigning column names
            if len(combined_df.columns) == 6:
                combined_df.columns = ["Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹", "Ø§Ù„ÙƒÙ…ÙŠØ©", "Ø³Ø¹Ø± Ø§Ù„ÙˆØ­Ø¯Ø©", "Ø§Ù„Ø¹Ø¯Ø¯", "Ø§Ù„ÙˆØµÙ", "Ø§Ù„Ø¨Ù†Ø¯"]
            else:
                combined_df.columns = [f"col_{i}" for i in range(len(combined_df.columns))]

            # Add metadata columns
            combined_df["Invoice Number"] = invoice_number
            combined_df["Invoice Date"] = invoice_date
            combined_df["Customer Name"] = customer_name
            combined_df["Address"] = address
            combined_df["Paid"] = paid_value
            combined_df["Balance"] = balance_value
            combined_df["Source File"] = pdf_path.name

            all_rows.append(combined_df)
        else:
            st.warning(f"âš ï¸ No valid tables found in {pdf_path.name}")
    except Exception as e:
        st.error(f"âŒ Error in {pdf_path.name}: {e}")
    return all_rows

# =========================
# Streamlit App UI
# =========================

st.title("ğŸ“„ Arabic Invoice Table Extractor")

uploaded_files = st.file_uploader("Upload PDF files or a ZIP of PDFs", type=["pdf", "zip"], accept_multiple_files=True)

if uploaded_files:
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_dir = Path(temp_dir)
        pdf_paths = []

        # Unpack and handle ZIP or single/multiple PDFs
        for uploaded_file in uploaded_files:
            file_path = temp_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            if uploaded_file.name.endswith(".zip"):
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_dir)
                pdf_paths += list(temp_dir.glob("*.pdf"))
            else:
                pdf_paths.append(file_path)

        # Safe temp folder
        safe_folder = temp_dir / "safe"
        safe_folder.mkdir(exist_ok=True)

        all_rows = []
        for pdf_path in pdf_paths:
            st.write(f"ğŸ“„ Processing: {pdf_path.name}")
            extracted = process_pdf(pdf_path, safe_folder)
            all_rows.extend(extracted)

        if all_rows:
            final_df = pd.concat(all_rows, ignore_index=True)

            # Cleaning
            final_df["Customer Name"] = final_df["Customer Name"].astype(str).str.replace(r"Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„\s*[:ï¼š]?\s*", "", regex=True).str.strip(" :ï¼šï¹•")
            final_df["Address"] = final_df["Address"].astype(str).str.replace(r"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†\s*[:ï¼š]?\s*", "", regex=True).str.strip(" :ï¼šï¹•")

            for col in ["Paid", "Balance"]:
                final_df[col] = final_df[col].astype(str).str.replace(r"[^\d.,]", "", regex=True).str.replace(",", "", regex=False).astype(float)

            if "Ø§Ù„Ø¹Ø¯Ø¯" in final_df.columns:
                final_df["Ø§Ù„Ø¹Ø¯Ø¯"] = pd.to_numeric(final_df["Ø§Ù„Ø¹Ø¯Ø¯"], errors="coerce")
            if "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹" in final_df.columns:
                final_df["Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹"] = final_df["Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹"].astype(str).str.replace(r"[^\d.,]", "", regex=True).str.replace(",", "", regex=False).astype(float)
                final_df["VAT 15% Calc"] = (final_df["Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹"] * 0.15).round(2)
                final_df = final_df.rename(columns={
                    "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹": "Total before tax",
                    "Ø³Ø¹Ø± Ø§Ù„ÙˆØ­Ø¯Ø©": "Unit price",
                    "Ø§Ù„Ø¹Ø¯Ø¯": "Quantity",
                    "Ø§Ù„ÙˆØµÙ": "Description",
                    "Ø§Ù„Ø¨Ù†Ø¯": "SKU"
                })
                final_df["Total after tax"] = (final_df["Total before tax"] + final_df["VAT 15% Calc"]).round(2)

            final_columns = [
                "Invoice Number", "Invoice Date", "Customer Name", "Address", "Paid", "Balance",
                "Total before tax", "VAT 15% Calc", "Total after tax",
                "Unit price", "Quantity", "Description", "SKU", "Source File"
            ]

            # Keep only available columns
            final_df = final_df[[col for col in final_columns if col in final_df.columns]]

            # Export Excel
            output_excel = temp_dir / "Cleaned_Combined_Tables.xlsx"
            final_df.to_excel(output_excel, index=False)

            st.success("âœ… Extraction complete!")
            st.download_button("ğŸ“¥ Download Cleaned Excel", output_excel.read_bytes(), file_name="Cleaned_Invoices.xlsx")
        else:
            st.warning("âš ï¸ No valid tables found.")
